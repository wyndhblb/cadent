
##
## stats emiter
##
## it will emit the usual statsd metrics to the `graphite-relay` backend defined
## in `statsd-config.toml`
##
##  cadent --config=statsd-config.toml --prereg=statsd-prereg.toml
##


[statsd-regex-map]
listen_server="statsd-proxy" # which listener to sit in front of  (must be in the main config)
default_backend="statsd-proxy"  # failing a match go here

    [statsd-regex-map.accumulator]
    backend = "graphite-relay"  # farm to relay
    input_format = "statsd"
    output_format = "graphite"
    accumulate_flush = "10s"  # since this is going into a graphite ticking at 10s .. they should match
    random_ticker_start = true  # typically want this to not overwhelm (for statsd)  writer backends with everybody flushing at the same time
    options = [
            ["legacyNamespace", "true"],
            ["prefixGauge", "gauges"],
            ["prefixTimer", "timers"],
            ["prefixCounter", ""],  # legacy namespace
            ["globalPrefix", "stats"],
            ["globalSuffix", ""],
            ["percentThreshold", "0.90,0.95,0.99"]
    ]

    # Sub string type match
    [[statsd-regex-map.map]]
    substring=".marvel"  # ignore elastic search marvel stuff
    reject=true

    [[statsd-regex-map.map]]
    substring="kafka.consumer.FetchRequestAndResponseMetrics"
    reject=true

    [[statsd-regex-map.map]]
    substring="ReplicaFetcherThread"
    reject=true

    [[statsd-regex-map.map]]
    substring="kafka.server.FetcherLagMetrics"
    reject=true

    [[statsd-regex-map.map]]
    substring="kafka.log.log"
    reject=true

    [[statsd-regex-map.map]]
    substring="kafka.cluster.Partition"
    reject=true

