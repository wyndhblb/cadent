##
##  Mysql-Series ONLY writer
##
##  note the `backend = "BLACKHOLE"` below, this implys the Lines stop at the writer
##
##  Basically the same as cassandra blob writers
##


[statsd-proxy-map]
listen_server="statsd-proxy" # which listener to sit in front of  (must be in the main config)
default_backend="carbon2-proxy"  # failing a match go here

    [statsd-proxy-map.accumulator]
    backend = "BLACKHOLE"
#    backend = "carbon2-proxy"
    input_format = "statsd"
    output_format = "carbon2"
    random_ticker_start = false

    [[statsd-proxy-map.map]]
        noop="true"


[json-http-map]
listen_server="json-http" # which listener to sit in front of  (must be in the main config)
default_backend="carbon2-proxy"  # failing a match go here

    [json-http-map.accumulator]
    backend = "carbon2-proxy"
    input_format = "json"
    output_format = "carbon2"
    random_ticker_start = false

    [[json-http-map.map]]
        noop="true"


[graphite-proxy-map]
listen_server="carbon2-proxy" # which listener to sit in front of  (must be in the main config)
default_backend="carbon2-proxy"  # failing a match go here

    [graphite-proxy-map.accumulator]
    backend = "BLACKHOLE"
    input_format = "carbon2"
    output_format = "carbon2"
    random_ticker_start = false
    tag_mode = "all"

    # aggregate bin counts
    accumulate_flush = "1s"
    times = ["1s:1h", "5s:12h", "1m:168h"]

    # cache objects to be shared (or not) across the writer backends
    [[graphite-proxy-map.accumulator.writer.caches]]
        name="gorilla"
        series_encoding="gorilla"
        bytes_per_metric=2048
        max_metrics=1024000  # for 1 million points @ 1024 b you'll need lots o ram
        # max_time_in_cache="2m" # force a cache flush for metrics in ram longer then this number
        # broadcast_length="128" # buffer channel for pushed overflow writes


    [[graphite-proxy-map.accumulator.writer.caches]]
            name="gob"
            series_encoding="gob"
            bytes_per_metric=512
            max_metrics=1024000  # for 1 million points @ 1024 b you'll need lots o ram



    # primary write things to the mysql DB
    [graphite-proxy-map.accumulator.writer.metrics]
        name="my-metrics"
        driver = "mysql-triggered"
        dsn = "$ENV{MYSQL_USER:admin}:$ENV{MYSQL_PASS:}@tcp(localhost:3306)/cadent"
        cache = "gorilla"
        [graphite-proxy-map.accumulator.writer.metrics.options]
        expire_on_ttl = true  # this will run a periodic job to purge "TTLed" data


    [graphite-proxy-map.accumulator.writer.indexer]
        name="my-indexer"
        driver = "mysql"
        dsn = "$ENV{MYSQL_USER:admin}:$ENV{MYSQL_PASS:}@tcp(localhost:3306)/cadent"
        [graphite-proxy-map.accumulator.writer.indexer.options]
        writes_per_second=200

    # also push things to the kafka
    [graphite-proxy-map.accumulator.writer.submetrics]
        driver = "kafka"
        dsn = "127.0.0.1:9092"
        cache="gorilla"
        [graphite-proxy-map.accumulator.writer.submetrics.options]
            topic="cadent"
            encoding="json"  # either msgpack or json at the moment



    # no sub indexer here
    [graphite-proxy-map.accumulator.writer.subindexer]
         driver = "noop"


    [graphite-proxy-map.accumulator.api]
        base_path = "/graphite/"
        listen = "0.0.0.0:8083"

        use_metrics="my-metrics"
        use_indexer="my-indexer"

    # Sub string type match
    [[graphite-proxy-map.map]]
        substring=".marvel"  # ignore elastic search marvel stuff
        reject=true